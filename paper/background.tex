\section{Background}
\label{sec:background}

This section presents the background on memory allocators, and some important factors of allocators. 

\subsection{Memory Allocators}

\label{sec:allocator}
Memory allocators are typically responsible for managing virtual memory inside the user space by satisfying memory requests from applications. Typically, the number of small objects is significantly larger than that of big objects. Therefore, most allocators utilize different mechanisms to manage small and big objects. For big objects, allocators may obtain a block of memory from the OS directly during the allocation, and then return it to the OS upon the deallocation~\citep{Hoard}. For small objects,  allocators may utilize freelists to track freed objects upon deallocations. In order to reduce external fragmentation and encourage memory utilization, memory blocks are managed by size classes, and every allocation will be rounded to its next larger size class.  

Based on the management of small objects, allocators can be further classified into multiple types, such as sequential, BiBOP, and region-based allocators~\citep{DieHarder, Gay:1998:MME:277650.277748}. Region-based allocators are suitable for special situations where all allocated objects within the same region can be deallocated at once~\citep{Gay:1998:MME:277650.277748}, which does not belong to general-purpose allocators. Therefore, \MP{} mainly focuses on the other two types of allocators, where most popular allocator belongs to. 

For sequential allocators, subsequent memory allocations are satisfied in a continuous memory block. Typically, a pointer is utilized to track the starting position of available space~\citep{Cling}. After an allocation, the pointer is bumped to the end of the current object, which is also called as a \texttt{bump allocator}. For such allocators, objects with different sizes can be placed continuously. Upon the deallocation, a freed object is typically placed into the freelist of its size class. In order to get the size information, these allocators typically place the size information just before actual objects. Such allocators include the Linux allocator (originating from dlmalloc~\citep{dlmalloc}) and the Windows allocator~\citep{DieHarder}.  

BiBOP stands for ''Big Bag of Pages''~\citep{hanson1980}. For BiBOP-style allocators, one or multiple continuous pages are treated as a ``bag'', holding objects with the same size class. The metadata of heap objects, such as its size and availability information, is typically stored in a separate area. Thus, BIBOP-style allocators improve the security and reliability, by avoiding metadata corruption caused by buffer overflows. Many performance-oriented allocators, such as TcMalloc~\citep{TCMalloc}, \texttt{jemalloc}~\citep{jemalloc}, Hoard~\citep{Hoard}, Scalloc~\citep{Scalloc}, and most of secure allocators, such as OpenBSD~\citep{OpenBSD} and DieHarder~\citep{DieHarder}, belong to this type. BiBOP allocators may utilize freelists or bitmaps to manage the availability of objects. When using the bitmap, only one bit is sufficient to track the availability of an object, which may introduce less memory overhead for the metadata, but possibly with a higher performance overhead due to the manipulation of the bitmap and the loss of the temporal information.  


\subsection{Important Factors of Memory Allocators}

\label{sec:factors}

Each memory allocator has its own design choices, with respect to the performance, scalability, and memory consumption. In this Section, some common factors of designing a well-performed allocator with low memory overhead are discussed, which consists of the basis for \MP{}'s design. \MP{} aims to understand these important factors. 

\subsubsection{Performance}
\label{sec:performance}

The performance of a memory allocator depends on two aspects: the performance overhead of its memory management, and its friendliness to a specific application. 

Memory management overhead mainly includes the allocation and deallocation overhead, which could be measured by the averaged runtime of each allocation and deallocation. The  direct metrics for this are the number of instructions and the contention, where the contention is further described in Section~\ref{sec:scalability}. In addition, hardware events (e.g., cache misses and TLB misses), or OS-related events(e.g., page faults), may also significantly affect the runtime of each allocation and deallocation. %Based on our evaluation, the DieHarder allocator traverses all possible bags to place a freed object back, causing up to 10$\times$ slowdown. %\todo{Maybe we could show the per-deallocation overhead of DieHarder to other allocators}.    

Application friendliness indicates that an allocation could actually benefit from the memory allocations of this allocator. Based on our understanding, multiple factors, such as cache utilization rate, page utilization rate, and false sharing effect, will significantly impact the performance (and therefore should be measured). An allocator with a low cache utilization rate may lead to more cache misses, since more cache lines are required to hold the same amount of data. Due to the similar reason, an allocator with a low page utilization rate could introduce more page faults and more TLB misses. 

\subsubsection{Scalability} 
\label{sec:scalability}

The scalability of an allocator can be affected by both hardware and software contention. Hardware contention is mostly related to cache contention. Software contention includes user space contention and kernel contention. 

Modern allocators supporting multithreaded applications typically utilize multiple arenas~\citep{dlmalloc} or per-thread heaps~\citep{Hoard}, in order to reduce user space contention. For instance, allocations will be satisfied from per-thread heaps and deallocations will be placed into per-thread freelists, without requiring a lock~\citep{TcMalloc, jemalloc}. In order to reduce memory blowup caused by multiple heaps~\citep{Hoard}, allocators also maintain a central heap to balance the memory usage: when the number of freed objects in a per-thread heap is larger than a threshold, objects will be moved to a central heap; when a per-thread heap is running out of memory, it obtains freed objects from the central heap before obtaining from the OS directly. However, using the central heap may introduce lock contention, impacting the scalability.  

 
 Allocators may introduce kernel contention by invoking memory-related system calls, such as \texttt{mmap}, \texttt{munmap}, \texttt{madvise}, \texttt{mprotect}. These system calls will be conflicted with each other and with the page fault handler.  In Linux, these system calls will acquire a per-process lock whenever manipulating the page table or virtual memory, which is also required for the page fault handler. During our experiments, we have discovered that one version of Linux kernel slows down an application by more than 40\% due to extensive invocations of system calls. Therefore, it is also important to measure the kernel space contention for memory allocators.
 
\subsubsection{Memory Consumption}
\label{sec:memoryconsumption}

Memory consumption is a very important factor to evaluate a memory allocator. Memory consumption will come from multiple aspects. First, it may come from the metadata consumption. Sequential allocators (e.g., the Linux allocator) may use multiple bytes to store the size information of each object, while a BiBOP allocator may only use one bit for each object. Second, it may come from the internal fragmentation caused by using coarse-grained size classes. For instance, Hoard manages objects with power-of-2 sizes~\citep{Hoard}, which may waste the memory if the required size is not power-of-2. Third, memory allocators may come from \textit{memory blowup}, when objects freed by one thread cannot be utilized by a different thread. The memory blowup is the most serious factor of memory consumption, based on our evaluation. Last, memory consumption may come from external fragmentation or other reasons. For instance, a secure allocator may voluntarily skip some objects in order to tolerate buffer overflows~\citep{DieHard}. 

%Almost all allocators manage heap objects by size classes, instead of using exact sizes, but with different size classes: some only support power-of-2 sizes, such as Hoard~\citep{Hoard}, DieHarder~\citep{DieHarder} or the OpenBSD allocator~\citep{OpenBSD}, while some utilize more fine-grained size classes, such as TcMalloc~\citep{TCMalloc} and jemalloc~\citep{jemalloc}. For each allocation request, the allocator will round up the requested size to the nearest size class. Upon each deallocation, the deallocated object will be threaded into the corresponding free list (for the freelist design) or the corresponded bit will be cleared (for the bitmap design). Although size classes reduce the external fragmentation, they may introduce \textit{internal fragmentation}, wasting the space between the actual allocated size and the size class. 


