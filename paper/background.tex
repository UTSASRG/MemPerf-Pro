\section{Background and Overview}
\label{sec:background}

This section presents the background about memory allocators, and some important factors of allocators. Then the basic idea of \MP{} is presented. 

\subsection{Background of Allocator}

\label{sec:allocator}
Memory allocators are typically responsible for managing virtual memory inside the user space by satisfying memory requests from applications. Since the number of small objects is significantly larger than that of big objects, most allocators utilize different mechanisms to manage small and big objects. For big objects, allocators may obtain a block of memory from the OS directly during the allocation, and then return it to the OS upon the deallocation~\citep{Hoard}. For small objects, allocators may utilize freelists or bitmaps to track freed objects upon deallocations. In order to reduce external fragmentation and encourage memory utilization, memory blocks are managed by size classes, and every allocation will be rounded to its next larger size class.  

Based on the management of small objects, allocators can be further classified into multiple categories, such as sequential, BiBOP, and region-based allocators~\citep{DieHarder, Gay:1998:MME:277650.277748}. Region-based allocators are suitable for special situations that all allocated objects within the same region are deallocated together~\citep{Gay:1998:MME:277650.277748}, which do not belong to general-purpose allocators. Therefore, \MP{} mainly focuses on the other two categories of allocators, where most popular allocators belong to. 

For sequential allocators, subsequent memory allocations are satisfied in a continuous memory block. Typically, a pointer is utilized to track the starting position of available space~\citep{Cling}. After an allocation, the pointer is bumped to the end of the current object, which is also called as bump-pointer allocators. For such allocators, objects with different sizes can be allocated continuously. Upon the deallocation, a freed object is typically placed into the freelist of its size class. The size information of each object is typically placed just before the object. Such allocators include the Linux allocator (originating from dlmalloc~\citep{dlmalloc}) and the Windows allocator~\citep{DieHarder}.  

BiBOP stands for ''Big Bag of Pages''~\citep{hanson1980}. For BiBOP-style allocators, one or multiple continuous pages are treated as a ``bag'', using to hold objects with the same size class. The metadata of heap objects, such as its size and availability information, is typically stored in a separate area. Thus, BiBOP-style allocators improve the security and reliability, by avoiding metadata corruption caused by buffer overflows. Many performance-oriented allocators, such as TcMalloc~\citep{tcmalloc}, \texttt{jemalloc}~\citep{jemalloc}, Hoard~\citep{Hoard}, Scalloc~\citep{Scalloc}, and most of secure allocators, such as OpenBSD~\citep{OpenBSD} and DieHarder~\citep{DieHarder}, belong to this type. BiBOP allocators may utilize freelists or bitmaps to manage the availability of objects. When using the bitmap, only one bit is sufficient to track the availability of an object, which may introduce less memory overhead for the metadata, but possibly with a higher performance overhead due to the manipulation of the bitmap and the loss of temporal locality.  


\subsection{Important Metrics of Allocator}

\label{sec:factors}

Every memory allocator has its own design choices. But they share some similar factors, such as performance, memory, scalability, and application-friendliness. This section will list important metrics for these factors, which are also reported by \MP{}. 

\subsubsection{Performance}
\label{sec:performance}

The performance of using a memory allocator depends on two aspects, the performance overhead of its memory management operation, or application-friendliness to a specific application (as discussed in Section~\ref{sec: friendliness}). We focus on the former one here. 

The performance overhead can be evaluated with the average number of instructions and the average runtime for each allocation and deallocation. The average data is more intuitive and understandable than the summary value. As described above, a memory allocator has different execution paths for different types of allocations/deallocations. Therefore, \MP{} further differentiates the type of memory operation during the profiling, such as new or re-used allocations for small objects, deallocations for small objects, and allocations/deallocations for large objects. By doing this, \MP{} is able to identify an issue inside one particular execution path. 
%\MP{} relies on a configuration file to obtain the threshold between small and big objects, and . 

In order to reveal a specific design issue, \MP{} further collects the averaged number of instructions, cache misses, and TLB misses for each operation, which are important reasons for the performance issue. For instance, a large number of instructions possibly indicates an inefficient design of an allocator. 

\subsubsection{Memory Consumption}
\label{sec:memoryconsumption}

Memory consumption is a serious concern across different platforms. Therefore, it is important to memory consumption/waste of a memory allocator. Sometimes, an allocator may waste more memory than memory leaks of an application. 

%The memory overhead of an allocator comes from multiple aspects, including metadata overhead, internal fragmentation, external fragmentation, memory blowup, or explicit objects skipping. 
Based on our understanding, memory consumption of an allocator may have multiple sources. First, it may originate from metadata, such as the memory to track the size or availability of every heap object. 


Second, it may come from internal fragmentation caused by using size classes.  As discussed above, memory allocators utilize multiple size classes to manage heap objects, instead of using the exact size. The difference between the requested size and the size of the corresponding class is internal fragmentation, which cannot be utilized to satisfy other requests. For instance, Hoard manages objects with power-of-2 sizes~\citep{Hoard}, which may waste the memory if the requested size is not power-of-2. 
 
Third, memory allocators may come from memory blowup. Memory blowup occurs due to the use of multiple heaps for the scalability purpose, where memory deallocations from one heap cannot be utilized to satisfy  subsequent memory requests from another thread~\cite{Hoard}. 
%In order to solve this issue, Li et. al. employ heuristics to adjust the synchronization frequency dynamically~\cite{DBLP:conf/iwmm/LiLD19}. 
Since modern allocators typically utilize per-thread heaps or multiple arenas to reduce the contention overhead, memory blowup is a big source of memory consumption. But it is challenging to profile memory blowup, as further described in Section~\ref{sec:profilingmemory}.   

Fourth, memory consumption may come from external fragmentation. External fragmentation occurs, when the total amount of the available memory is sufficient to satisfy a request but fail to do so due to non-contiguous memory. External fragmentation is also related to the use of size classes, because allocators rarely or never perform objects coalescing and splitting.
Sometimes, it is impossible to change the size class for few objects inside the bag, since BiBOP-style allocators typically use a single size for all objects in the whole bag. 
%That is, objects cannot be changed to other size classes, until all objects in the whole bag are freed. 
%This design may cause extensive external fragmentation overhead. 

 Last, some secure allocators may voluntarily skip some objects in order to tolerate buffer overflows~\citep{DieHard, DieHarder, Guarder}. If a buffer overflow lands on non-used objects, it will cause no harm to the applications. However, it is extremely difficult to differentiate explicit skipping and external fragmentation. 


Overall, for memory consumption, \MP{} reports the number and portion of real memory usage, internal fragmentation, memory blowup, and other overhead separately. Other overhead includes external fragmentation, metadata overhead, and the sum of skipped objects. It is difficult for \MP{} to have the precise information about metadata and the sum of skipped objects. Therefore, \MP{} reports a summary for other memory overhead by subtracting the mentioned ones from the total memory usage. For the total memory usage, \MP{} tracks memory related system calls (e.g., \texttt{mmap} or \texttt{sbrk}). 
%Overall, \MP{} provides real memory usage of t
%\MP{} also reports real memory usage by tracking memory allocations and deallocations.  


\subsubsection{Scalability} 
\label{sec:scalability}

The scalability of an allocator can be affected by both hardware and software contention. Hardware contention is mostly related to cache or page contention, which is discussed in Section~\ref{sec: friendliness}. Software contention is the focus here, further including user space contention and kernel contention. 

\paragraph{User Space Contention} User space contention of an allocator is typically caused by the use of locks inside memory management operations. Based on our observation, different allocators have significant behaviors on lock usage. Some allocators, such as TcMalloc~\citep{tcmalloc} or jemalloc~\citep{jemalloc}, minimize the use of locks via per-thread cache. If an allocation can be satisfied from a per-thread cache, there is no need to acquire a lock. However, some allocators, such as Hoard~\citep{Hoard}, acquire at least a lock for each allocation, although with its per-thread heap. Some allocators, such as DieHarder and OpenBSD, utilize a central heap (and a lock) for each size class, causing too much contention. 

%The average time for each lock acquisition indicates potential lock contention inside. The average time of each critical section helps expose whether the lock contention is due to the heavy workload inside the critical section or not. For instance, if the contention is high, but the average time inside the critical section is low, then this allocator should employ more fine-grained locks to distribute its overhead. In contrast, if the average time inside the critical section is high, then the allocator should possibly move some computation out of the critical section or simplify its management. 

To evaluate user space contention, \MP{} collects per acquisition data, per-operation data, per-lock data, and total information of locks. Per-acquisition data includes the runtime of each lock acquisition and the runtime of each critical section. For per operation, \MP{} reports the number of locks and the average runtime of per-acquisition for different operations, such as new small allocation, re-used small allocation, small deallocation, and large allocation and deallocation.  Further, \MP{} reports the total number of locks inside the allocator, and then reports the number of acquisitions, the contention rate, and the number of acquisitions for each operation for every suspicious lock that may have contention issue. 
 
\paragraph{Kernel Space Contention} 
 An allocator may introduce kernel contention by invoking memory-related system calls frequently, such as \texttt{mmap}, \texttt{munmap}, \texttt{madvise}, and \texttt{mprotect}. These system calls may conflict with each other and with the page fault handler. By examining the source code of the Linux kernel, they all acquire a process-based lock (e.g. \texttt{mmap\_sem}) upon the entry of these system calls, causing kernel contention. Based on our evaluation, a version of the Linux allocator slows down an application by more than 20\%, due to extensive invocations of the \texttt{madvise} system call. Therefore, it is important to measure  kernel space contention caused by an memory allocator. \MP{} proposes to utilize the average runtime of each system call to evaluate potential kernel contention, without the change of the kernel code.

For kernel contention, \MP{} reports the average time and the number of invocations for each memory-related system call. Since different operations (e.g., small and large allocation) have different execution paths, \MP{} further reports the number for each particular operation. The differentiation helps identify an issue that may only appear in a particular operation. 

\subsubsection{Application Friendliness}
\label{sec: friendliness}

Application friendliness indicates whether memory allocations are tapped with access patterns of an application. Sometimes, application friendliness may have a bigger impact on the performance than memory management performance. For instance, TcMalloc typically has a less memory management overhead than the default allocator, but runs around $48\times$ slower  for \texttt{cache-thrash}. The major reason is that TcMalloc introduces both active and passive false sharing~\cite{tcmallocsharing}. \MP{} reports multiple important metrics that evaluate application-friendliness. 


The first parameter is cache utilization rate. Cache utilization rate is the percentage of words that are actually holding actual objects. An allocator with a high cache utilization rate will cause less cache misses, benefiting the overall performance. Multiple reason may affect the cache utilization rate. First, some allocators (e.g., the Linux allocator) that prepend the metadata just before each object may reduce  cache utilization rate. Every cache load operation will load the metadata that is not referenced during normal memory access. 
 Second, a coarse-grained size class may also reduce cache utilization rate, due to internal fragmentation. Third, freed objects that are not reutilized timely may also cause a low cache utilization rate. 

 %Similarly, if page utilization rate is low, it may cause high TLB misses and prohibitive memory consumption. \MP{} samples memory accesses, and checks the corresponding cache utilization rate and page utilization rate. Overall, \MP{} could report an average cache utilization rate and page utilization rate over all samples. 

The second parameter is page utilization rate. Page utilization rate indicates the percentage of a page that are actively utilized for holding actual data. An allocator with a higher page utilization rate will introduce less page faults and less Translation Lookaside Buffer (TLB) misses. Page utilization rate can be caused by the similar reasons as cache utilization rate.  

The third parameter is active/passive false sharing. False sharing indicates that multiple threads are concurrently accessing different words in the same cache line. Active false sharing is introduced upon first allocations of objects, where an allocator cannot allocate continuous objects in the cache line to the same thread. Passive false sharing is introduced upon deallocations, where a freed object will be utilized by another thread and then cause false sharing in the same cache line. 

The fourth parameter is cache contention rate outside the allocation. Cache misses can be caused by conflicting or falsely-shared misses. Upon cache misses, the data has to be loaded from the main memory, which is much slower than accessing the cache directly. 

Overall, \MP{} reports cache utilization rate, page utilization rate, cache contention rate, and false sharing effect. For false sharing effect, \MP{} not only reports the number of cache lines that have active and passive false sharing, but also reports the rate of conflicting accesses. The reported result also helps explain the performance slowdown issue. 
%employs the PMU hardware to collect these parameters. It employs the PMU-based sampling to sample memory accesses, and collects the data of cache and page utilization data upon sample events, as described in Section~\ref{sec:profilefriendliness}. \MP{} employs PMU to collect cache misses/page faults outside memory management.

\subsubsection{Summary of Important Metrics}

As described above, \MP{} reports many important metrics of an allocator, as further described in Table~\ref{table:metrics}. These metrics help answer whether an allocator is the culprit of performance issue, and help identify a particular design issue inside the allocator. Table ~\ref{table:metrics} also provides collection techniques for specific metrics, which is further discussed in Section~\ref{sec:idea}. 

\begin{table}[h]
  \centering
  \footnotesize
 % \setlength{\tabcolsep}{1.0em}
\begin{tabular}{l | l | l}
\hline
Category & Important Metrics & Collection Techniques \\ \hline
\multirow{2}{*}{Performance} & {Alloc/Free runtime} & Timestamp\\ \cline{2-3}
& {Cache misses, page faults, TLB misses, instructions} & Performance Monitoring Units (PMU) \\ \hline
\multirow{4}{*}{Memory} & Internal fragmentation & \\ \cline{2-3}
	& Memory blowup &  \\ \cline{2-3}
& {Other overhead (e.g., external fragmentation)} &  \\ \cline{2-3}
& Real memory usage & \\ \hline
\multirow{2}{*}{Scalability} & \specialcell{User space contention: per-lock data} & Timestamp\\ \cline{2-3}
& {Kernel space contention: per-syscall data} &  Timestamp \\ \hline
\multirow{3}{*}{Application Friendliness} & Cache/page utilization rate & PMU  \\ \cline{2-3}
& False sharing effect &  PMU\\ \cline{2-3}
& Cache contention rate &  PMU \\ \hline
  \end{tabular}
  \centering
  \caption{Important metrics and collection methods.\label{table:metrics}}
\end{table}



