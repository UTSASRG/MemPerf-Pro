To evaluate the memory consumption, we  evaluate \MP{} with glibc-2.28. In total, the memory consumption with \MP{} is around $2.6\times$ more than that without \MP{}, where the specific data is skipped due to the page limitation. Overall, the memory overhead for applications with large footprint is typically smaller, comparing to applications with small footprint. 

\todo{Confirming this based on the impact: Multiple reasons may contribute to \MP{}'s memory overhead. First, \MP{} maintains per-page information to track memory usage and measure page utilization rate, and per-cacheline information to measure cache utilization rate. Second,  \MP{} adds an additional hash table to store all allocated objects, in order to differentiate new and re-used allocations, and adds significant memory overhead to storing the data of each object. Third, \MP{} stores per-thread counters for each size class, including the counters for internal fragmentation and active allocations, which will reduce the contention caused by using the global counters by trading the memory overhead for the performance. }

%For instance, \MP{} imposes around $2.6\times$ memory overhead for \texttt{canneal}, due to 8.7 million new allocations. 
 

%In total, \MP{} introduces 53.6\% memory overhead. It has different behaviors for applications with large footprint (with the original memory consumption larger than 100 MB) and with small footprint. The average memory overhead for applications with large footprint is 179\%, but it is $45\times$ for small footprint applications. For instance, for \texttt{freqmine} and \texttt{linear\_regression}, \MP{} only adds $68.1\%$ and $2.3\%$ separately. 

%Based on our analysis, \MP{} will introduce more memory overhead for the Linux allocators than other allocations. The basic reason is that the default Linux allocator has 8265size classes. 



%Some applications have higher ratios of memory overheads with MMProf and ones without MMProf, such as vips. One reason is that MMProf uses some per-size variables to calculate memory distributions.  For our evaluation, Glibc-2.28 has 8265 classes, therefore MMProf's per-size variable would cost more space than running other allocators. Meanwhile, vips has lower scale than other applications, which make its ratios look high.But actually, for applications with medium scales(more than 100MB memory overhead when running alone), our evaluation shows MMProf's memory overheads ratio are always lower than 3.
\begin{comment}

\begin{table}[!tp]  
\centering
    \caption{Memory consumption of \MP{}\label{tab:memory_consumption}}
\begin{tabular}{l r r }    
\hline    
Applications &  Default  & With \MP{}\\  \hline  
 \multicolumn{3}{c}{Small Footprint (> 100MB)}		\\
blackscholes & 628681 & 1011985 \\ 
canneal & 872241 & 1934704 \\ 
dedup & 1194100 & 2393497 \\ 
facesim & 322069 & 714020 \\ 
ferret & 125513 & 346869 \\ 
fluidanimate & 231920 & 558696 \\ 
freqmine & 3513129 & 5904754 \\ 
histogram & 1376432 & 1509108 \\ 
larson & 345286 & 435672 \\ 
linear\_regression & 5830226 & 5963057 \\ 
pca & 502980 & 827778 \\ 
raytrace & 1317749 & 2198701 \\ 
reverse\_index & 1147026 & 1842073 \\ 
streamcluster & 114602 & 315606 \\ 
string\_match & 1636385 & 1769350 \\ 
threadtest & 524588 & 1142986 \\ 
x264 & 1029130 & 1178769 \\  \hline
\textbf{Total} &  20712057 & 30047625 \\ 
\textbf{Average} &  & 179\% \\  \hline
 \multicolumn{3}{c}{Small Footprint (< 100MB)}		\\
bodytrack & 33070 & 213612 \\ 
cache-scratch & 3450 & 152028 \\ 
cache-thrash & 3896 & 155926 \\ 
kmeans & 22538 & 203553 \\ 
matrix\_multiply & 50161 & 197894 \\ 
swaptions & 7676 & 160146 \\ 
vips & 94312 & 283276 \\ 
word\_count & 3129 & 729449 \\ \hline 
\textbf{Total} & 218232&  2095884 \\   
\textbf{Average} & & 4506\%  \\ \hline
   \end{tabular}
   \end{table}
	
\end{comment}
