\begin{comment}

\begin{table}[h]
  \centering
  \caption{Abnormal metrics of allocators for different applications.\label{table:abnormal}}
  \footnotesize
  \setlength{\tabcolsep}{0.2em}
\begin{tabular}{l | l | l | l | l}
\hline
Applications & Allocator & Behavior & Abnormal Metrics & Root Cause \\ \hline
cache-thrash & TcMalloc & $47.7\times$ slowdown & Contention rate for PFS lines: 50\% & Root Cause \RN{1} \\ \hline
dedup & glibc-2.21 & 20\% slowdown &  \# of Madvise for small allocations: & Root Cause \RN{2} \\ \hline
freqmine & jemalloc &  Memory consumption & memory blowup: 2174230K (37\%) & Root Cause \RN{3} \\ 
 & &  & external fragmentation: 1132045K (19\%) \\ \hline
swaptions  &  DieHarder  & $9\times$ slowdown  & 
	Small reused alloc: 377476 cycles 	& Root Cause \RN{4} \\
& & & Small free: 331745 cycles, and 4.9 cache misses & \\ 
& & & Per-lock acquisition: 353448 cycles & \\\cline{4-5}
& & & External fragmentation: 1878K(37\%) & Root Cause \RN{5} \\
& & & cache utilization 55\%, page utilization 35\% & \\\cline{2-5}
& Hoard & $6.3\times$ slowdown & 
	Small reused alloc: 68933 cycles, 9.4 cache misses 	& Root Cause \RN{6} \\
	
& & & Small free: 53402 cycles, 11.8 cache misses & \\ 
& & & 1.54 locks per-operation & \\
\cline{4-5}
& & & Memory blowup: 4789K( 81\%) & Root Cause \RN{7} \\
& & & cache utilization 62\%, page utilization 51\% & \\\cline{2-5}
& OpenBSD & $8\times$ slowdown & Small re-used alloc: 98962 cycles, 4.5 cache misses & Root Cause \RN{8}\\ 
& & & Small free: 101081 cycles, 7 cache misses & \\ 
& & & 1.1 locks per-operation &  \\ \hline
  \end{tabular}
\end{table}
\end{comment}


%issues of allocators that were detected by \MP{}.
%The detailed data reported by \MP{} will be presented in order to show the helpfulness of its report. 

\paragraph{TcMalloc:}
%TcMalloc typically performs very well in almost all applications, except \texttt{cache-thrash} and  \texttt{cache-scratch}. For instance,
TcMalloc runs $38.3\times$ slower than the default allocator for \texttt{cache-thrash}. \MP{} reports the runtime of allocations and deallocations of TcMalloc, which is at a normal range. But it reports around 18\% cache invalidation rate for all sampled instructions, which is the major reason causing the significant slowdown. This application will actually have both active and passive false sharing in \texttt{TcMalloc}. 
%TcMalloc actually experiences both active and passive false sharing issues. 
For active false sharing, TcMalloc will get one object for a thread from its central heap each time, so that two continuous objects can be utilized by two different threads. Upon the deallocation, TcMalloc always places a freed object to the current thread's per-thread cache, which may introduce passive false sharing that two objects in the same cache line are accessing by different threads. We have performed a very simple experiment to confirm whether this is the major cause. All allocations were aligned to the size of cache line, e.g., 64 bytes. We believe that this simple change will avoid false sharing issue. With this simple change, \texttt{cache-trash}'s runtime were reduced from 200 seconds to 5.17 seconds, which is similar to other allocators. 
%In comparison, the Linux allocator always returns an object back to its original arena, avoiding passive false sharing.  
%TcMalloc also has 8\% internal fragmentation and 8\% external fragmentation for \texttt{swaptions}, which explains that why it has more memory overhead than other allocators. 

\paragraph{glibc-2.21:}  For \texttt{dedup}, glibc-2.21 has a known bug that may invoke excessively large number of \texttt{madvise} systems calls under certain memory use patterns~\cite{madvise}. \MP{} reports 505241 \texttt{madvise} invocations in 8.6 seconds, and the runtime of each \texttt{madvise} is about $12266$ cycles (much higher than the normal one). \texttt{madvise} introduces high kernel contention with page faults and memory-related system calls. Changing the threshold of shrink\_heap reduces the runtime from 8.6 seconds to 6.9 seconds (with 20\% improvement), which is similar to that of other allocators.

%\MP{} also reports 52\% memory wastes caused by memory blowup for this application. That helps explain why glibc-2.21 are using 740 MB more memory than TcMalloc.  

%\paragraph{jemalloc:} jemalloc typically has good performance, but has a greater memory consumption caused by both memory blowup and external fragmentation. For \texttt{freqmine} application, jemalloc has 43\% memory wastes caused by blowup. That helps explain that why it consumes 40\% more memory than TcMalloc, and 38\% more than glibc-2.21. In comparison, TcMalloc only has 2\% memory wastes and glibc-2.21 has 7\% memory wastes.  
\paragraph{Hoard:} 
For \texttt{swaptions}, \texttt{Hoard} is running around $2.07\times$ slower than the default allocator. \MP{} reports abnormal lock information related with medium-size objects (between 256 bytes and 8K bytes): it acquires 1.9 locks per new allocation, 1.73 locks per re-used allocation, and 2.73 locks per free operation. 
%These operations also incur 14\%, 18\% and 14\% lock contention separately. In addition to that, \MP{} reports that the average cycles of each lock is more than 400 cycles, which is much more than 30~70 cycles for the serial phase. 
Multiple locks per operation is caused by Hoard's hash mechanism: ``we use a simple hash function to map thread ids to per-processor heaps....., there is not a one-to-one correspondence between threads and processors''~\cite{Hoard}. Because multiple threads can be mapped to the same heap, Hoard introduces a lock to protect each heap. That will introduce too much locks for each memory management operation. Instead,  TcMalloc and jemalloc's per-thread buffer do not have this issue. 

In addition to that, \MP{} further reports abnormal lock contention rate for one lock, 87\% for new allocations and 47\% for re-used allocations in parallel phase. Therefore, we utilized the debugger to identify the reason: Hoard has a threshold (defined in hoardThresholdFunctionClass) for returning a super-block back into the global pool of super-blocks based on the emptiness. Unfortunately, one deallocation could cause the current super-block to be placed into the global pool, while the next allocation will move the super-block back to the thread-local buffer. That is, the back-and-forth of moving the super-block introduces high contention on the lock of protecting the super-block pool. We changed the threshold from 64K to 4K to reduce the migration, where this single change improves the runtime from 26.17 seconds to 12.76 seconds. \textit{This is a new bug that is never reported elsewhere}. 

\paragraph{DieHarder:} DieHarder runs $5.75\times$ slower than the default Linux allocator for \texttt{swaptions}. This application reflects multiple design issues of DieHarder. First, \MP{} reports an abnormally high amount of cache misses for each deallocation (around 112). Based on our investigation, DieHarder checks all miniheaps to identify the original location of an object, which introduces multiple cache misses due to the checking on multiple miniheaps. Second, \MP{} reports that DieHarder has one lock acquisition per allocation and five lock acquisitions per deallocation, with 44\% and 47\% lock contention rate for small and big allocations. The data actually shows multiple design issues of DieHarder, which  acquires too many locks and uses the global lock. 

%\textit{Root Cause \RN{5}}: we also notice that DieHarder introduces external fragmentation, around 37\%. As described before, this also includes the size of skipped objects, which is caused by DieHarder's over-provision allocation mechanism. Since DieHarder will also randomly choose some objects, that is maybe the cause of its low cache utilization and page utilization. 




%Also, its overhead of using many levels of templates cannot completely go away, since Hoard has a lot of code like this: SmallHeap::malloc(), or getHeap().malloc(), Heap::malloc(). Based on our evaluation on an application (canneal) with a big number of allocations, the allocation cycles for a new allocation for Hoard will be around 520 cycles, which is 2.8X of TcMalloc (180 cycles). The cycles for a re-used allocation will be 187 cycles, which is 2.3X times of TcMalloc (83 cycles). The number of instructions is also multiple times more than TcMalloc.

%Hoard also has 40\% memory wastes for \texttt{swaptions}, where 26\% is from its external fragmentation.  
 
%\paragraph{OpenBSD:} \textit{Root Cause \RN{8}:}  OpenBSD has $8\times$ slowdown for \texttt{swaptions}, comparing to the default allocator. Based on its report, we find out that OpenBSD has the similar issue as Hoard, since it acquires more than one lock for each operation. By checking the code, we find out that OpenBSD has the same global lock for all allocations and deallocations, which is the possible reason for its big slowdown. Also, OpenBSD also has a big cache misses for its re-used allocations and deallocations for small objects, which is possibly another reason why it has a big slowdown. For OpenBSD, we also observe that it has significant big number of instructions than other allocators, which as 430 instructions for deallocating a small object, and 295 instructions for a re-used allocation. This is possibly another reason for its big slowdown. 

%\paragraph{jemalloc:}
%During evaluation, the \texttt{reverse\_index} benchmark was found to perform approximately 21\% slower when paired with \texttt{jemalloc} versus the default Linux allocator. Upon inspection, we find that, with \texttt{jemalloc}, the program exhibited over $2x$ the number of CPU cycles associated with the deallocation execution path, as well as a 34\% increase in critical section duration (i.e., the cycles spent within outermost critical sections).




