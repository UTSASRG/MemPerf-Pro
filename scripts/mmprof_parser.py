#!/usr/bin/env python3

"""
File: test_parser.py
Author: Stefen Ramirez
Email: Stfnrmz0@gmail.com
Description: Reads any mmprof test file and averages metadata
"""

import argparse
import csv
import re
import sys

from collections import defaultdict
from fnmatch import fnmatch
from pprint import pprint

try:
    from openpyxl.styles import Font, PatternFill
    from openpyxl import Workbook
except ImportError:
    pass

# Set required arguments: i.e just the test files to read
parser = argparse.ArgumentParser(description='Parse a set of tests from mmprof library',
                                 prefix_chars='-+')

parser.add_argument('files', metavar='test', type=str, nargs='+',
                    help='test file output generated by mmprof library')

# All optional functions: exclude/included certains allocators, etc. And set output files
parser.add_argument('-o', '--output', metavar='output-file', type=str,
                    help='send output out to file')

parser.add_argument('--export', '-e', type=str, choices=['excel', 'csv', 'text'],
                    help='export to excel, csv, or text')

parser.add_argument('--allocator', dest='included_allocators', default=[],
                    type=str.lower, nargs='+', help='Process only specific allocators')

parser.add_argument('--exclude-allocator', dest='excluded_allocators', default=[],
                    type=str.lower, nargs='+', help='Exclude specific allocators')

parser.add_argument('--keyword', dest='included_keywords', default=[],
                    type=str.lower, nargs='+', help='Only print certain keywords')

parser.add_argument('--exclude-keyword', dest='excluded_keywords', default=[],
                    type=str.lower, nargs='+', help='Exclude keywords from output')

parser.add_argument('--debug', action='store_true',
                    help='Set debugging for testing mmprof files')

# Regex for section matching: "-----memory----" or ">>>> from freelist <<<<<"
title_regex = re.compile(r'[\>-]+([\s\w]+)[-\<]+')

# Regex for ignoring whitespace lines
blank_line_regex = re.compile(r'^\s*$')

# Regex for data reading each line: "malloc faults  48" or ">>> realloc faults  0"
data_regex = re.compile(r'^([a-zA-Z\s_\(\)]+?)\s*(\d+)\s*$')


def generate_table(output):
    for program_data in output:
        for program, allocators in program_data.items():
            headers = ['metadata']
            complete_dataset = defaultdict(lambda: ['NaN' for _ in range(len(allocators.keys()))])

            # For the set of values found set the values for the allocator if it has one
            i = 0
            for allocator, dataset in allocators.items():
                headers.append(allocator)
                for k, v in dataset.items():
                    complete_dataset[k][i] = v
                i += 1

            yield(program, headers, complete_dataset)


def valid_attribute(included, excluded, var):
    var = var.lower()
    checkit = lambda x: list(filter(lambda y: fnmatch(var, y), x))
    if len(included) is 0 and len(excluded) is 0:
        return True
    elif checkit(included) and len(checkit(excluded)) is 0:
        return True
    elif checkit(included) is 0 and checkit(excluded):
        return True
    else:
        return False


def export_to_excel(output):
    """Generates a excel file by the output"""
    def set_max_cell_size(ws):
        dims = {}
        for row in ws.rows:
            for cell in row:
                if cell.value:
                    dims[cell.column] = max((dims.get(cell.column, 0), len(str(cell.value))))
        for col, value in dims.items():
            ws.column_dimensions[col].width = value + (value * .25)

    workbook = Workbook()
    worksheet = workbook.active
    for prg_name, headers, dataset in generate_table(output):
        worksheet.title = prg_name
        worksheet.append(headers)
        for col in range(1, len(headers) + 1):
            worksheet.cell(row=1, column=col).font = Font(bold=True, name='Calibri')
        # For all data found; insert the key and its values as a row
        for row in ([[k] + v for k, v in dataset.items()]):
            worksheet.append(row)

        # Make it readable
        set_max_cell_size(worksheet)
        worksheet = workbook.create_sheet()
    workbook.save(args.output)
    workbook.close()
    print("Written to {}".format(args.output))


def export_to_text(output):
    with open(args.output, 'w') as f:
        print_metadata(output, file=f)
        print("Written to {}".format(f.name))


def export_to_csv(output):
    for name, headers, dataset in generate_table(output):
        with open(name + '_' + args.output, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=['allocator'] + list(dataset.keys()))
            writer.writeheader()
            for index, allocator in enumerate(headers[1:]):
                built_row = {}
                built_row['allocator'] = allocator
                for key in dataset.keys():
                    built_row[key] = dataset[key][index]
                writer.writerow(built_row)
            print("Written to {}".format(csvfile.name))


def export_output(output):
    if args.export == 'excel':
        try:
            Workbook
        except NameError:
            print("Failed to export: You need to install openpyxl from pip3")
            sys.exit(1)
        export_to_excel(output)
    elif args.export == 'csv':
        export_to_csv(output)
    else:
        export_to_text(output)


def print_metadata(output, file=sys.stdout):
    for name, headers, dataset in generate_table(output):
        print('{:=^{length}}'.format(name.upper(), length=((len(headers) + 1) * 20)), file=file)
        row_format = '{:<40}' + '{:>20}' * (len(headers) - 1)
        print(row_format.format(*headers), file=file)
        print('-' * ((len(headers) + 1) * 20), file=file)
        for k, v in dataset.items():
            print(row_format.format(k, *v), file=file)


def process_metadata(datalines):
    """Parse a set of metadata and extract the key and value
       into a dict"""
    metadata = defaultdict(lambda: {'total': 0, 'visits': 0})
    for line in datalines:
        data = data_regex.match(line)
        if data is not None:
            key, value = data.groups()
            metadata[key]['total'] += int(value)
            metadata[key]['visits'] += 1
    return metadata


def section(file):
    """Generates a single section from the file
       returns the title and everyline within that section"""
    lines = []
    title = file.name
    for line in file:
        title_match = title_regex.match(line)
        if title_match is not None:
            yield title.title(), lines
            title = title_match.group(1).strip()
            lines.clear()
        elif blank_line_regex.match(line) is None:
            lines.append(line.strip('> \n'))


def parse_file_data(file):
    """Parses all data from file and returns a hash of all titles
       and their metadata"""
    metadata = {}
    with open(file) as f:
        for title, lines in section(f): # For each seperated section the file
            new_metadata = process_metadata(lines)
            metadata[title] = defaultdict(lambda: {'total': 0, 'visits': 0})
            for k, v in new_metadata.items():
                metadata[title][k]['total'] += v['total']
                metadata[title][k]['visits'] += v['visits']
    return metadata


def analyze_files(files):
    """Gets the total averages across all files passed"""
    total_metadata = defaultdict(lambda: {'total': 0, 'visits': 0})
    for file in files:
        file_metadata = parse_file_data(file)
        for title, sections in file_metadata.items():
            for k, v in sections.items():
                file_metadata[title][k] = (v['total'] / v['visits'])
                total_metadata[k]['total'] += v['total']
                total_metadata[k]['visits'] += v['visits']
    return {k: round(v['total'] / v['visits'], 2) for k, v in total_metadata.items() if valid_attribute(args.included_keywords, args.excluded_keywords, k)}


def group_files(files):
    """Group a set of files by program by and then by allocator used"""
    groups = defaultdict(dict)
    for filename in files:
        try:
            if args.debug is True:
                title, allocator = filename.split('-')[0:2]
            else:
                title = filename.split('-')[0]
                formatted = filename.replace(title, '')
                allocator = formatted.replace('_', '-').split('-')[2].lower()
            title = title.split('/')[-1]
        except Exception as e:
            print('Invalid test file passed: {}'.format(filename))
            continue
        if valid_attribute(args.included_allocators, args.excluded_allocators, allocator):
            groups[title].setdefault(allocator, []).append(filename)
    return groups


def check_export_flags():
    if args.export and not args.output:
        parser.error('Output filename required with export: -o/--output filename')
    elif args.output and not args.export:
        print('Warning: output filename specifed but no export method set')
    elif args.export == 'csv':
        print('CSV export will create a file for each program.')
        answer = input('Are you sure you want csv? [y/n] ')
        if 'no'.startswith(answer.lower()):
            sys.exit(0)


def extract_metadata(files):
    """Main processor for each file."""
    file_group = group_files(files)
    total_data = []
    for program, allocators in file_group.items():
        program_data = {program: {}}
        for allocator, files in allocators.items():
            program_averages = analyze_files(files)
            program_data[program][allocator] = program_averages
        total_data.append(program_data)
    return total_data


if __name__ == '__main__':
    args = parser.parse_args()
    check_export_flags()
    metadata = extract_metadata(args.files)
    if args.export:
        export_output(metadata)
    else:
        print_metadata(metadata)
